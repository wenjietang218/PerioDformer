nohup: ignoring input
Args in experiment:
Namespace(random_seed=2024, is_training=1, model_id='traffic_336_96', model='PerioDformer', data='custom', root_path='./dataset/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, w=1, C=42, mlp_num=1, d_model2=64, d_ff2=256, experiment=2, dimension=24, percent=5, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=862, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=0, itr=1, train_epochs=80, batch_size=16, patience=10, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.2, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
线性头的参数量为： 963
>>>>>>>start training : traffic_336_96_PerioDformer_custom_ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_1_42_1_64_256__exp2_dim24_5_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 11849
val 1661
test 3413
43
torch.Size([16, 336, 43])
torch.Size([16, 144, 43])
Training with5% of the variates.
当前GPU已分配内存：0.027149200439453125 GB
GPU已分配内存的峰值：1.023038387298584 GB
	iters: 100, epoch: 1 | loss: 0.8266413
	speed: 0.1170s/iter; left time: 6914.2569s
	iters: 200, epoch: 1 | loss: 0.7652465
	speed: 0.1022s/iter; left time: 6032.5742s
	iters: 300, epoch: 1 | loss: 0.5814495
	speed: 0.1020s/iter; left time: 6009.9849s
	iters: 400, epoch: 1 | loss: 0.4480374
	speed: 0.1024s/iter; left time: 6018.6788s
	iters: 500, epoch: 1 | loss: 0.4793648
	speed: 0.1019s/iter; left time: 5979.6423s
	iters: 600, epoch: 1 | loss: 0.3904906
	speed: 0.1025s/iter; left time: 6005.7426s
	iters: 700, epoch: 1 | loss: 0.3399168
	speed: 0.1030s/iter; left time: 6024.0620s
Epoch: 1 cost time: 77.24004173278809
43
Traceback (most recent call last):
  File "D:\model\PerioDformer\run_longExp.py", line 152, in <module>
    exp.train(setting)
  File "D:\model\PerioDformer\exp\exp_main.py", line 275, in train
    vali_loss = self.vali(vali_data, vali_loader, criterion)
  File "D:\model\PerioDformer\exp\exp_main.py", line 124, in vali
    batch_y_sliced = batch_y_sliced[:, -self.args.pred_len:, f_dim:].to(self.device)
KeyboardInterrupt
